{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS IMPLEMENTATION OF TRANSFORMER ARCHETECHTURE ON THE EMAIL DETECTION PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. DATA REFORMATTING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Result\n",
      "0                                           forecast       0\n",
      "1  traveling business meeting take fun trip espec...       0\n",
      "2                        test test successful way go       0\n",
      "3  randy send schedule salary level everyone sche...       0\n",
      "4                            hello let shoot tuesday       0\n",
      "(519977, 2)\n"
     ]
    }
   ],
   "source": [
    "# load data from final_df.csv\n",
    "final_df = pd.read_csv('final_df.csv')\n",
    "\n",
    "# print head\n",
    "print(final_df.head())\n",
    "print(final_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nan values \n",
    "final_df = final_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(518920, 2)\n"
     ]
    }
   ],
   "source": [
    "# print shape\n",
    "print(final_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOW BUILD A CLASS FOR TRANSFORMER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, embed_size: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embed(x) * torch.sqrt(self.embed_size) # i still don't know why we multiply by sqrt of embed_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size: int = 512, max_len: int = 500, dropout: float):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.max_len = max_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.posi_embed = nn.Embedding(max_len, embed_size)\n",
    "\n",
    "        # create a zero matrix \n",
    "        pe = torch.zeros(max_len, embed_size)\n",
    "        # create the pos vector\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # calculate the div term\n",
    "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * -(np.log(10000.0) / embed_size))\n",
    "        # calculate the pos for even numbers starts from 0\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        # calculate the pos for odd numbers starts from 1\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0) \n",
    "\n",
    "        # save the pe as along with model\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + (self.pe[:, :x.shape(1), :]).requires_grad_(False) # fixed\n",
    "\n",
    "        return self.dropout(x) # prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalizing(nn.Module):\n",
    "    def __init__(self, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(1)) # change 1 to embed_size if needed\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim = True)\n",
    "        std = x.std(-1, keepdim = True)\n",
    "        norm_x = (x - mean) / (std + self.eps)\n",
    "        return self.alpha * norm_x  + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module): # one hidden layer feed forward network\n",
    "    def __init__(self, embed_size: int, ff_hidden_size: input = 2048, dropout: float):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.ff_hidden_size = ff_hidden_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(embed_size, ff_hidden_size)\n",
    "        self.fc2 = nn.Linear(ff_hidden_size, embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.dropout(torch.relu(self.fc1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadEncoder(nn.Module):\n",
    "    def __init__(self, embed_size: int, n_heads: int = 128, dropout: float):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.n_heads = n_heads\n",
    "        assert embed_size % n_heads == 0, \"Embedding size must be divisible by number of heads\"\n",
    "\n",
    "        self.head_size = embed_size // n_heads\n",
    "        self.W_q = nn.Linear(embed_size, embed_size)\n",
    "        self.W_k = nn.Linear(embed_size, embed_size)\n",
    "        self.W_v = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "        self.W_o = nn.Linear(embed_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, Q, K, V, mask):\n",
    "        Q_p = self.W_q(Q)\n",
    "        K_p = self.W_k(K)\n",
    "        V_p = self.W_v(V)\n",
    "        # slice the Q, K, V to heads\n",
    "        Q_p = Q_p.view(Q_p.shape[0], Q_p.shape[1], self.n_heads, self.head_size).transpose(1, 2)\n",
    "        K_p = K_p.view(K_p.shape[0], K_p.shape[1], self.n_heads, self.head_size).transpose(1, 2)\n",
    "        V_p = V_p.view(V_p.shape[0], V_p.shape[1], self.n_heads, self.head_size).transpose(1, 2)\n",
    "\n",
    "        # calculate the attention\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(Q, K, V, mask, dropout):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(Q.shape[-1], dtype = torch.float32))\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = torch.softmax(scores, dim = -1)\n",
    "        scores = dropout(scores)\n",
    "        output = torch.matmul(scores, V)\n",
    "        return output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
